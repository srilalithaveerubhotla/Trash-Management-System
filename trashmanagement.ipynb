{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trashmanagement.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilalithaveerubhotla/Trash-Management-System/blob/master/trashmanagement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBG82j4-8zDH",
        "colab_type": "text"
      },
      "source": [
        "##**TRASH MANAGEMENT SYSTEM**\n",
        "\n",
        "[<img src=\"https://github.com/srilalithaveerubhotla/Trash-Management-System/blob/master/TrashImages.jpg?raw=true\" width=\"1000\" height=\"300\" align=\"center\">]()\n",
        "\n",
        "[<img src=\"https://github.com/shubham0204/Privacy_Policy_Texts/blob/master/notebook_button_two.png?raw=true\" width=\"150\" height=\"50\" align=\"center\">](https://github.com/garythung/trashnet)\n",
        "\n",
        "\n",
        "\n",
        "[<img src=\"https://github.com/srilalithaveerubhotla/Trash-Management-System/blob/master/tensorboard-logo-social.png?raw=true\" width=\"300\" height=\"200\" align=\"right\">](https://tensorboard.dev/experiment/9OqkrQuOT4uvh0JNSmGf8g/#scalars&run=20200516-232647%2Ftrain)\n",
        "## **This is a final project code for CMPE 258 Final Project Course work**\n",
        "\n",
        "###Guided By : Vijay Eranti\n",
        "\n",
        "###Team Memebers : \n",
        "\n",
        "###1.   Srilalitha Veerubhotla\n",
        "###2.   Shreyus Puthiyarapurail\n",
        "###3.   Atul Shah\n",
        "###4.   Shailesha Prasad Maganahalli\n",
        "\n",
        "Idea of this project Trash Classification which we used the dataset which has six classes: glass, paper, cardboard, plastic, metal, and trash. Currently, the dataset consists of 2527 images:\n",
        "\n",
        "501 glass\n",
        "\n",
        "*  501 glass\n",
        "*  594 paper\n",
        "*  403 cardboard\n",
        "*  482 plastic\n",
        "*  410 metal\n",
        "*  137 trash\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "which this pictures are already been taken by the auther mentioned in the above link.\n",
        "We wrote distinct variety of Deep Learning Models to address the basic image classification technique.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This notebook Follows as below..\n",
        "\n",
        "1. Data Importing\n",
        "2. Data Pre-Processing\n",
        "3. Data Visualisations with TensorBoard Dev\n",
        "4. CNN ARCHITECTURES with Hyper parameter Tuning \n",
        "5. Metrics and Loss Functions \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wSL-SzBFQQU",
        "colab_type": "text"
      },
      "source": [
        "##DATA IMPORTING \n",
        "\n",
        "---versioning----\n",
        "\n",
        "Keras Version:  >3.0\n",
        "\n",
        "TensorFlow version:  2.2.0\n",
        "\n",
        "TensorBoard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu4nYpLnCZf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy\n",
        "import glob\n",
        "import pylab as plt\n",
        "import os\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "# importing libraries\n",
        "from matplotlib import pyplot\n",
        "from keras import datasets\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "# importing Image class from PIL package  \n",
        "from PIL import Image  \n",
        "\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
        "from keras.models  import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
        "import random,os,glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from kerastuner.tuners import RandomSearch\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from keras.utils import print_summary, to_categorical\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
        "from datetime import datetime\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "# %tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Vn26ogiJ8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mounting Drive and accessing the datafiles required\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsVr8IppF_96",
        "colab_type": "text"
      },
      "source": [
        "Load Garbage Classification zip file to google drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOnuRYF2nENA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzipping the file \n",
        "\n",
        "!unzip /content/drive/My\\ Drive/garbage-classification.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2G_38-qGRQH",
        "colab_type": "text"
      },
      "source": [
        "Annotated Images are stored in different files as per thier labels to access the files and their annotations from folder names below lines of code is used "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsilLSTEiJ_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing and deriving the training images and labelling them\n",
        "trash_images = []\n",
        "labels = [] \n",
        "for fruit_dir_path in glob.glob(\"/content/garbage classification/Garbage classification/*/\"):\n",
        "    fruit_label = fruit_dir_path.split(\"/\")[4]\n",
        "    \n",
        "    # Path for reading the files\n",
        "    for image_path in glob.glob(os.path.join(fruit_dir_path, \"*.jpg\")):\n",
        "\n",
        "      # Using cv2 readig the images from path\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Resizing the images\n",
        "        image = cv2.resize(image, (70, 70))\n",
        "\n",
        "        # Colour Transformations \n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "        \n",
        "        trash_images.append(image)\n",
        "        labels.append(fruit_label)\n",
        "        # Appending and deriving the final images \n",
        "\n",
        "trash_images = np.array(trash_images)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58zinSfGiKEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the Key-value dictonaries of the annotations into labels \n",
        "\n",
        "label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\n",
        "id_to_label_dict = {v: k for k, v in label_to_id_dict.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUHQ-MzfiKGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_label_id = np.array([label_to_id_dict[i] for i in labels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zgIpJlvlQwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking the shape of the data \n",
        "\n",
        "print(\"Train_data shape......:\",trash_images.shape)\n",
        "print(\"Labels shape..........:\",training_label_id.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39KRzsDFlwWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into Train and Test\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(trash_images, training_label_id, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi-vklch6tc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensor Board Integration by giving the approriate log location with the time stamp \n",
        "\n",
        "now = datetime.now()\n",
        "logdir = \"logs/trash_images/\" + now.strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", np.reshape(trainX[0:10],(-2,70,70,3)), step=0)\n",
        "file_writer.set_as_default()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAr0S6hl7fBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execution of TensorBoard at every step\n",
        "\n",
        "%tensorboard --logdir logs/trash_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh4E3IZe9q20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path for the image folders\n",
        "\n",
        "dir_path = '/content/garbage classification/Garbage classification'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZJCgLhj9wuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_list = glob.glob(os.path.join(dir_path, '*/*.jpg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJj0PMHB90EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking the Length of the images\n",
        "\n",
        "len(img_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClF7eyrRImog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VISUALISING THE IMAGE \n",
        "  \n",
        "# creating a object  \n",
        "Image.open('/content/garbage classification/Garbage classification/plastic/plastic136.jpg')  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrSrpW_JQxA",
        "colab_type": "text"
      },
      "source": [
        "## IMAGE ARGUMENTATION\n",
        "Arranging the image size, scale, width, height, and rescale, flipping "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5268yDn9h_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ---------Using Image Data Generator below code allows you to do the argumentation on the -----------------\n",
        "##------------ mentioned parameters and sets your image positions---------------------\n",
        "\n",
        "#_------------------- Generating for Train Image------------------\n",
        "train=ImageDataGenerator(horizontal_flip=True,\n",
        "                         vertical_flip=True,\n",
        "                         validation_split=0.1,\n",
        "                         rescale=1./255,\n",
        "                         shear_range = 0.1,\n",
        "                         zoom_range = 0.1,\n",
        "                         width_shift_range = 0.1,\n",
        "                         height_shift_range = 0.1,)\n",
        "\n",
        "# ------------------Generating for test Image ------------------------\n",
        "\n",
        "test=ImageDataGenerator(rescale=1/255,\n",
        "                        validation_split=0.1)\n",
        "\n",
        "train_generator=train.flow_from_directory(dir_path,\n",
        "                                          target_size=(300,300),\n",
        "                                          batch_size=32,\n",
        "                                          class_mode='categorical',\n",
        "                                          subset='training')\n",
        "\n",
        "test_generator=test.flow_from_directory(dir_path,\n",
        "                                        target_size=(300,300),\n",
        "                                        batch_size=32,\n",
        "                                        class_mode='categorical',\n",
        "                                        subset='validation')\n",
        "\n",
        "#---------------------------Generating the validation dataset -------------------\n",
        "\n",
        "validation_generator = test.flow_from_directory(\n",
        "    dir_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=0\n",
        ")\n",
        "\n",
        "labels = (train_generator.class_indices)\n",
        "print(labels)\n",
        "\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "print(labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f17QYEHjKQzA",
        "colab_type": "text"
      },
      "source": [
        " LABELS: {'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n",
        "{0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}\n",
        "\n",
        "Train Images : 2276\n",
        "\n",
        "Test Images :  251"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXE9QHzk-HkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From the generator creating the labels and actual images \n",
        "\n",
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Z0QT_D-LKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "Labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(Labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dpyuvyOR_lt",
        "colab_type": "text"
      },
      "source": [
        "## Simple CNN Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58UtoGdp-NXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# SETTING THE SEEDS FOR RANDOM \n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model=tf.keras.Sequential()\n",
        "\n",
        "#------------------------------CONVOLUTIONAL BLOCKS------------------------------\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3), padding='same',input_shape=(300,300,3),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2)) \n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3), padding='same',activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2)) \n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3), padding='same',activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2)) \n",
        "\n",
        "#--------------------------CLASSIFICATION LAYERS--------------------------------\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "#-----------------------------OUTPUT DENSE LAYER-------------------------------\n",
        "model.add(tf.keras.layers.Dense(6,activation='softmax'))\n",
        "\n",
        "# FILEPATH FOR SAVING THE MODEL LOGS\n",
        "filepath=\"/content/trained_model.h5\"\n",
        "logdir=\"logs/trash_images/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#TENSORBOARD INTEGRATION\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# MODEL CHECK POINTS\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"trash_simple_model.h5\", save_best_only=True)\n",
        "callbacks_list = [model_checkpoint,tensorboard_callback]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoRpItrF-RsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------MODEL SUMMARY-------------\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNftt_FGxqXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------PLOTTING THE MODEL AS PNG FILE ------------\n",
        "keras.utils.plot_model(model, \"simple_cnn_trash.png\", show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adnJdTFa-WHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------------Compiling the model with categorical cross entropy as loss function and \n",
        "#. ADAM as optimiser with acuuracy and Mean Square Error and metrics---------------------------------------\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc','mse']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbjEDQoX-Zlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------- MODEL FITTING WITH EPOCHS, WORKERS, BY INITIATING THE CALL BACKS AND VALIDATION ON DATA---------------------\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=10,\n",
        "                              steps_per_epoch=2276//32,\n",
        "                              validation_data=test_generator,\n",
        "                              validation_steps=251//32,\n",
        "                              workers = 4,\n",
        "                              callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VKK6PRSIrrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------PRINTING THE LEARNING RATE USED----------------------\n",
        "print(K.eval(model.optimizer.lr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkqW0nLU5EYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-----------------------UPLOADING THE LOGS TO TENSORBOARD DEV-----------------------\n",
        "!tensorboard dev upload --logdir logs/trash_images/ \\\n",
        "  --name \"Trash Management\" \\\n",
        "  --description \"Training results from https://colab.sandbox.google.com/github/tensorflow/tensorboard/blob/master/docs/tbdev_getting_started.ipynb\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8LDWsJdd78B",
        "colab_type": "text"
      },
      "source": [
        "## Simple CNN Fine Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO57c6gLeBQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=tf.keras.Sequential()\n",
        "\n",
        "#------------------------------THREE CONVOLUTIONAL BLOCKS------------------------------\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3), padding='same',input_shape=(300,300,3),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2)) \n",
        "model.add(tf.keras.layers.Dropout(0.5)) # No accuracy\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64,(3,3), padding='same',activation='selu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2)) \n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3), padding='same',activation='selu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2)) \n",
        "\n",
        "#-------------------------- FOUR CLASSIFICATION LAYERS WITH DROPOUT--------------------------------\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(126,activation='selu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(64,activation='selu'))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense(32,activation='selu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(16,activation='selu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "#-----------------------------OUTPUT DENSE LAYER-------------------------------\n",
        "\n",
        "model.add(tf.keras.layers.Dense(6,activation='softmax'))\n",
        "\n",
        "\n",
        "# FILEPATH FOR SAVING THE MODEL LOGS\n",
        "filepath=\"/content/trained_model.h5\"\n",
        "logdir=\"logs/trash_images/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "#TENSORBOARD INTEGRATION\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "# MODEL CHECK POINTS\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"trash_simple_model1.h5\", save_best_only=True)\n",
        "callbacks_list = [model_checkpoint,tensorboard_callback]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byI9r8tLd7Q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------MODEL SUMMARY-------------\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL9RjHCe-bw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------PLOTTING THE MODEL AS PNG FILE ------------\n",
        "\n",
        "keras.utils.plot_model(model, \"simple_cnn1_trash.png\", show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNjgc3cJfAvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------- MODEL COMPILING RMS PROP OPTIMISER WITH LEARNING RATE AS 0.0003 AND LOSS FUNCTION AS KULLBACK LEIBER DIVERGENCE \n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.003)\n",
        "model.compile(loss='kullback_leibler_divergence', optimizer=opt, metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ8TJ2rq_Hug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------- MODEL FITTING WITH EPOCHS, WORKERS, BY INITIATING THE CALL BACKS AND VALIDATION ON DATA---------------------\n",
        "\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=10,\n",
        "                              steps_per_epoch=2276//32,\n",
        "                              validation_data=test_generator,\n",
        "                              validation_steps=251//32,\n",
        "                              workers = 10,\n",
        "                              callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdIotFPXNkoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(K.eval(model.optimizer.lr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "260gF6dn80ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p classifier1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_NTUenzBFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#-----------------SAVING THE MODEL-----------------\n",
        "model_save_name = 'classifier1.h5'\n",
        "model.save('/content/trained_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIVHc77rzqoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------SAVING THE MODEL AS JSON FILE---------------\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpWbNMoSoYX7",
        "colab_type": "text"
      },
      "source": [
        "### VGG16 TRANSFER LEARNING Using Pretrained TOP NOTCH MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWV_6F0foA7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------------------NECESSARY IMPORTS FOR TRANSFER LEARNING PRETRAINED MODEL FOR VGG16---------------------------\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import optimizers, losses\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzBlsFmvmCqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-----------------------INSTANTIATING VGG16 TRANSFERLEARNED MODEL ----------------------\n",
        "model = VGG16()\n",
        "keras.utils.plot_model(model, \"simple_vgg16_tl_trash.png\", show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC6Hj4Y1ocKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2B6Mq-2pDFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "# load an image from file\n",
        "image = load_img('/content/garbage classification/Garbage classification/paper/paper357.jpg', target_size=(224, 224))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY1N2X5upk_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "# convert the image pixels to a numpy array\n",
        "image = img_to_array(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx9B1PJ2qgSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pyd6eH8qitp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3t7cMt2qlv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat = model.predict(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwRh7qmfqpXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import decode_predictions\n",
        "# convert the probabilities to class labels\n",
        "label = decode_predictions(yhat)\n",
        "# retrieve the most likely result, e.g. highest probability\n",
        "label = label[0][0]\n",
        "# print the classification\n",
        "print('%s (%.2f%%)' % (label[1], label[2]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN8InFBIQHrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/keras-pretrained-models.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yWWGlO4q1FQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------------USING THE SAVED MODEL VGG16 WEIGHTS IMPORTING AS A BASE MODEL FOR TRANSFER LEARNING----------------\n",
        "\n",
        "#------------------------------------DEFINING MORE LAYERS ON TOP OF VGG16 FOR TRANSFER LEARNING----------------------------\n",
        "\n",
        "\n",
        "base_model = VGG16(weights=None, include_top=False, input_shape=(70, 70, 3))\n",
        "base_model.load_weights('/content/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE_-cF-tYA_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------------------------generating necessary training and testing data---------------------\n",
        "gen = {\n",
        "    \"train\": ImageDataGenerator(\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        rescale=1. / 255,\n",
        "        validation_split=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        rotation_range=30,\n",
        "    ).flow_from_directory(\n",
        "        directory=dir_path,\n",
        "        target_size=(300, 300),\n",
        "        subset='training',\n",
        "    ),\n",
        "\n",
        "    \"valid\": ImageDataGenerator(\n",
        "        rescale=1 / 255,\n",
        "        validation_split=0.1,\n",
        "    ).flow_from_directory(\n",
        "        directory=dir_path,\n",
        "        target_size=(300, 300),\n",
        "        subset='validation',\n",
        "    ),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp7G2H9kSayn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------------------------SEQUENTIAL TENSORFLOW KERAS MODEL AND ADDING BASE MODEL TO IT--------------------\n",
        "#-----------------------ADDING GROUPAVERAGEPOOLING--------------------\n",
        "#-----------------------ADDING DROPOUT & DENSE LAYERS-----------------\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.15),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = tf.keras.optimizers.Nadam(learning_rate=0.002)\n",
        "\n",
        "#-------------MODEL COMPILING---------------------\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy','mse'])\n",
        "\n",
        "#-----------------------EPOCHS AND BATCH SIZE----------------\n",
        "batch_size = 200\n",
        "epochs = 10\n",
        "train_generator = gen[\"train\"]\n",
        "valid_generator = gen[\"valid\"]\n",
        "\n",
        "#-------------------------ADDING STEP EPOCHS AND VALIDATION SETPS FOR CALL BACKS--------------------------\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = valid_generator.n // batch_size\n",
        "\n",
        "\n",
        "#--------------------------MODEL SAVING, CHECK POINTING AND TENSORBOARD INTGRATION--------------------\n",
        "filepath = \"/content/vggpretrained.h5\"\n",
        "\n",
        "logdir=\"logs/trash_images/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"trash_simple_model1.h5\", save_best_only=True)\n",
        "callbacks_list = [model_checkpoint,tensorboard_callback]\n",
        "\n",
        "#--------------------------------MODEL FITTING----------------------------------------\n",
        "history = model.fit_generator(generator=train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                              validation_data=valid_generator, validation_steps=validation_steps,\n",
        "                              callbacks=callbacks_list)\n",
        "with open('trainHistoryDict.txt', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L30-jDCqa8jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorboard dev upload --logdir logs/trash_images/ \\\n",
        "  --name \"Trash Management\" \\\n",
        "  --description \"Training results from https://colab.sandbox.google.com/github/tensorflow/tensorboard/blob/master/docs/tbdev_getting_started.ipynb\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57GIVpr_2UWy",
        "colab_type": "text"
      },
      "source": [
        "## VGG 16 From Scratch code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4waSYsMdhG_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NILT_WMSBAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DEFINING MODEL SHAPE\n",
        "input_shape=(300,300,3)\n",
        "\n",
        "#---------------------STARTING THE SEQUENTIAL MODEL--------------------\n",
        "model =tf.keras.Sequential(name='VGG-16')\n",
        "\n",
        "# --------------------------------------CONVOLUTIONAL LAYERS WITH BATCH NORMALIZATION, DROPOUT,---------------------------------------------------\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same',input_shape=input_shape))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "#-------------------MAXPOOLING LAYER------------------------\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "#--------------------------------------CLASSIFICATION LAYERS--------------------------------\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "#-----------------------------OUTPUT DENSE LAYER-------------------------------\n",
        "model.add(tf.keras.layers.Dense(6))\n",
        "\n",
        "#------------------------------LOGISTIC REGRESSION LAYER----------------------\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dHgFSfTkDmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(model, \"simple_vgg16_scratch_trash.png\", show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q3hucjPClFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------------Compiling the model with BINARY cross entropy as loss function and \n",
        "#. ADAM as optimiser with acuracy metrics---------------------------------------\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "# train_generator = gen[\"train\"]\n",
        "# valid_generator = gen[\"valid\"]\n",
        "# batch_size = 200\n",
        "# epochs = 10\n",
        "\n",
        "# steps_per_epoch = train_generator.n // batch_size\n",
        "# validation_steps = valid_generator.n // batch_size\n",
        "logdir=\"logs/trash_images/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"trash_simple_model1.h5\", save_best_only=True)\n",
        "callbacks_list = [model_checkpoint,tensorboard_callback]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyNWRbTljiEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------- MODEL FITTING WITH EPOCHS, WORKERS, BY INITIATING THE CALL BACKS AND VALIDATION ON DATA---------------------\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=10,\n",
        "                              steps_per_epoch=2276//32,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=251//32,\n",
        "                              workers = 4,\n",
        "                              callbacks=callbacks_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui2LAaJTbN8_",
        "colab_type": "text"
      },
      "source": [
        "## INCEPTION V3 TOP Notch Transfer Learned"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNlS8azOO_Ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#---------------------------NECESSARY IMPORTS FOR TRANSFER LEARNING PRETRAINED MODEL FOR INCEPTIONV3---------------------------\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers, losses\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8nHjcAqP_yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------------------------INITIATING PRE-TRAINED INCEPTION MODEL WITH WEIGHTS---------------------------\n",
        "\n",
        "base_model = InceptionV3(weights=None, include_top=False, input_shape=(300, 300, 3))\n",
        "base_model.load_weights('/content/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "base_model.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB9zgAD8P_11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------------------------ADDING DENSE, DROPOUT AND POOLONG LAYERS TO THE PRETRAINED MODELS FOR TRANSFER LEARNING--------------------\n",
        "\n",
        "#------------------------------------DEFINING MORE LAYERS ON TOP OF INCEPTIONV3 FOR TRANSFER LEARNING----------------------------\n",
        "\n",
        "model = Sequential([    \n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.15),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "#----------------------RMSPROP OPTIMIZER WITH LEARNING RATE----------------------------\n",
        "opt = optimizers.rmsprop(lr=0.0002)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "#----------------------BATCH SIZING AND EPOCH-----------------------\n",
        "batch_size = 300\n",
        "epochs = 10\n",
        "train_generator = gen[\"train\"]\n",
        "valid_generator = gen[\"valid\"]\n",
        "\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = valid_generator.n // batch_size\n",
        "\n",
        "#--------------------------------------- FILEPATH FOR SAVING THE MODEL LOGS------------------------\n",
        "\n",
        "filepath = \"/content/model_inception_pre.h5\"\n",
        "\n",
        "\n",
        "# --------------------------------MODEL CHECK POINTS------------------------------------------------\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1]\n",
        "\n",
        "#-----------------------------------FITIING MODEL----------------------------------------\n",
        "history = model.fit_generator(generator=train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                              validation_data=valid_generator, validation_steps=validation_steps,\n",
        "                              callbacks=callbacks_list)\n",
        "with open('trainHistoryDict.txt', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fZO0Cc7aYTX",
        "colab_type": "text"
      },
      "source": [
        "## RESNET 50 top notch Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykL4g8R-QzMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------------------NECESSARY IMPORTS FOR TRANSFER LEARNING PRETRAINED MODEL FOR RESNET50---------------------------\n",
        "\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers, losses\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import pickle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXeg8Vkyaq2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------------------------INITIATING PRE-TRAINED INCEPTION MODEL WITH WEIGHTS---------------------------\n",
        "\n",
        "#------------------------------------DEFINING MORE LAYERS ON TOP OF RESNET50 FOR TRANSFER LEARNING----------------------------\n",
        "\n",
        "\n",
        "base_model = ResNet50(weights=None, include_top=False, input_shape=(300, 300, 3))\n",
        "base_model.load_weights('/content/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "base_model.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0dffqKxa6_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------------------------ADDING DENSE, DROPOUT AND POOLONG LAYERS TO THE PRETRAINED MODELS FOR TRANSFER LEARNING--------------------\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.15),\n",
        "    Dense(1024, activation='selu'),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "#----------------------ADAGRAD OPTIMIZER WITH LEARNING RATE----------------------------\n",
        "\n",
        "opt = optimizers.adagrad(lr=0.0003)\n",
        "\n",
        "#--------------------------MODEL COMPILING-----------------\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "#----------------------BATCH SIZING AND EPOCH-----------------------\n",
        "batch_size = 350\n",
        "epochs = 10\n",
        "train_generator = gen[\"train\"]\n",
        "valid_generator = gen[\"valid\"]\n",
        "\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = valid_generator.n // batch_size\n",
        "\n",
        "# --------------------------------MODEL CHECK POINTS------------------------------------------------\n",
        "filepath = \"/content/model_resnetpre.h5\"\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint1]\n",
        "\n",
        "#-------------------------------TRAINING MODEL--------------------------------------\n",
        "history = model.fit_generator(generator=train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                              validation_data=valid_generator, validation_steps=validation_steps,\n",
        "                              callbacks=callbacks_list)\n",
        "with open('trainHistoryDict.txt', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeSWENrVPLZZ",
        "colab_type": "text"
      },
      "source": [
        "## RESNET 50 SCRATCH CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYZSLvHjSY-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#---------------------------NECESSARY IMPORTS FOR TRANSFER LEARNING PRETRAINED MODEL FOR RESNET50---------------------------\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "#from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS-IoB8-RxT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \n",
        "    # ---------------------Defining name basis----------------------------\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # ------------------------Retrieve Filters---------------------------------\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # ---------------------------SAVE THE INPUT FILES------------------------\n",
        "    X_shortcut = X\n",
        "    \n",
        "    #---------------------- First component of main path---------------------\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # -----------------------Second component of main path-------------------------\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # ---------------------Third component of main path ------------------------------\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # ---------------------------Final step: Add shortcut value to main path, and pass it through a RELU activation---------------------\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpUxYb8jSJn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s=2):\n",
        "\n",
        "    # ---------------------------Defining name basis--------------------------\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # ---------------------------Retrieve Filters--------------------------\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # ----------------------------Save the input value----------------------\n",
        "    X_shortcut = X\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # ---------------------------FIRST COMPONENT---------------------------------\n",
        "    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # --------------------------SEOND COMPONENT------------------------------------\n",
        "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # --------------------------THIRD COMPONENT------------------------------------\n",
        "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    #####--------------------------- SHORTCUT PATH----------------------------- #### \n",
        "    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # -------------------------Final step: Add shortcut value to main path, and pass it through a RELU activation----------------------------------\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6LgnxMVPR10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
        "    \n",
        "    # --------------------Define the input as a tensor with shape input_shape----------------------\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # --------------------------Zero-Padding--------------------------------------------\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # -------------------------------STAGE 1-----------------------------------------\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # --------------------------------STAGE 2-----------------------------------------\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # ----------------------------------STAGE 3-----------------------------------------\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # ----------------------------------STAGE 4------------------------------------------\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # ---------------------------------STAGE 5----------------------------------------\n",
        "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    #------------------------- AVGPOOL------------------------\n",
        "    X = AveragePooling2D(pool_size=(2,2), padding='same')(X)\n",
        "\n",
        "    #------------------- OUTPUT DENSE LAYER---------------------\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # -----------------------MODEL CREATING--------------\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uc73UCaUKnT",
        "colab_type": "text"
      },
      "source": [
        "### DATA NORMALISATION AND CONVERTING LABELS INTO CATEGORIES "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH9LaRwITJjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------Normalize image vectors------------------------------\n",
        "X_train = trainX/255.\n",
        "X_test = testX/255.\n",
        "\n",
        "#-------------------------------Convert training and test labels to one hot matrices---------------------\n",
        "Y_train = to_categorical(trainY, 6)\n",
        "Y_test = to_categorical(testY, 6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdk2EQ_ZUMnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------------------------------- PRINTING THE SHAPE OF THE TRAIN AND TEST DATA----------------------------\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voKZnTYqPR5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------------------------------------------------------COMPILING THE SCRATCH CODE FUNCTION--------------------\n",
        "model = ResNet50(input_shape = (70, 70, 3), classes = 6)\n",
        "keras.utils.plot_model(model, \"simple_RESNET_trash.png\", show_shapes=True)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a9fn8u5PR8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#--------------------------------------------training model------------------------------------\n",
        "model.fit(X_train,Y_train, epochs = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKJZmpE6ceF4",
        "colab_type": "text"
      },
      "source": [
        "## MobileNet Transfer Learned Top Notch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4reFdpmVzE2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------------------------INSTANTIATING THE MOBILENETV2 PRE-TRAINED MODEL ------------------------------------\n",
        "IMG_SHAPE = (224,224,3)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False, \n",
        "                                               weights='imagenet')\n",
        "base_model.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTLODoUbbBPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#------------------------------------DEFINING MORE LAYERS ON TOP OF MOBILENETV2 FOR TRANSFER LEARNING----------------------------\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(6, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LShYTGqcrJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------------------------------------------------COMPILING THE CODE----------------------------------\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), #Adam(), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ou3GxDScwyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------------------------------BATCH SIZING, EPOCHS & CHECKING POINTING-----------------------------\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "steps_per_epoch = train_generator.n // batch_size\n",
        "validation_steps = validation_generator.n // batch_size\n",
        "\n",
        "#----------------------------TRAINING THE MODEL----------------------------------------------\n",
        "\n",
        "history = model.fit_generator(train_generator, \n",
        "                              steps_per_epoch = steps_per_epoch,\n",
        "                              epochs=epochs, \n",
        "                              workers=4,\n",
        "                              validation_data=validation_generator, \n",
        "                              validation_steps=validation_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ChXm8L5lDJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------MODEL SAVING--------------------------\n",
        "model_save_name = 'mobilenet-transfer.h5'\n",
        "model.save('/content/mobilenet-transfer.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz4hOsWf5kkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}